<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LSTM-based deep learning framework：short-term wind speed series</title>
      <link href="/2020/09/03/Hexo-Theme-Snail/"/>
      <url>/2020/09/03/Hexo-Theme-Snail/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/Aiyi1208" target="_blank" rel="noopener">View My Github Here </a></p><h1 id="LSTM-based-deep-learning-framework-short-term-wind-speed-series-prediction"><a href="#LSTM-based-deep-learning-framework-short-term-wind-speed-series-prediction" class="headerlink" title="LSTM-based deep learning framework: short-term wind speed series prediction"></a>LSTM-based deep learning framework: short-term wind speed series prediction</h1><h2 id="A-B-S-T-R-A-C-T："><a href="#A-B-S-T-R-A-C-T：" class="headerlink" title="A B S T R A C T："></a>A B S T R A C T：</h2><p>​     Wind power is recognized as an ideal renewable energy source. While alleviating the existing energy crisis, it can also reduce environmental pollution caused by fossil fuels. Accurate and stable wind speed prediction is essential for the effective management of wind farms and energy systems. However, due to the inherent random nonlinear fluctuation characteristics of wind speed changes, it is difficult to obtain satisfactory forecast results. Taking into account the poor prediction performance of traditional statistical methods, this article aims to combine neural network models, especially deep learning models, with data preprocessing techniques to improve wind speed prediction accuracy.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>   This paper mainly uses empirical mode decomposition technology (EMD) to deconstruct and reorganize the original wind speed data, reduce the original wind speed noise, and reduce the chaos and volatility of the sequence. The pre-processed data is passed into the neural network prediction model for prediction. Also, the difference between the prediction performance of the deep learning model (LSTM) and the traditional neural network is mainly discussed.</p><p><img src="https://s1.ax1x.com/2020/09/04/wFh6qe.png" alt="wFh6qe.png"><br>​                  <strong>Fig.1.</strong> <em>Newly installed wind power capacities of seven leading markets in 2019</em></p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>   Introduced data preprocessing technology and long short-term memory neural network (LSTM), and discussed the specific strategy of the combined model.</p><h4 id="Data-preprocessing-technology"><a href="#Data-preprocessing-technology" class="headerlink" title="Data preprocessing technology"></a>Data preprocessing technology</h4><p>​     EMD was first proposed by Huang et al. It is a time series decomposition technique for nonlinear and non-stationary series. The EMD decomposition algorithm performs adaptive decomposition according to the characteristics of the data itself, without prerequisites. Therefore, it has obvious advantages in processing the decomposition of the original sequence, and is widely used in the research of signal decomposition and noise reduction processing.</p><p><strong>The specific steps of EMD are as follows:</strong></p><p>​     <em>Step1</em>: Suppose the original time series is <em>Y(t)</em> , and calculate all local extreme points (including maximum and minimum) of the sequence.</p><p>​    <em>Step2</em>: Perform cubic spline interpolation on all extreme points, and then connect to generate upper envelope <em>U(t)</em> and lower envelope <em>L(t)</em>. All points of the original sequence are between the upper and lower envelopes.</p><p>​    <em>Step3:</em> Find the mean value of each point of the upper and lower envelope：</p><script type="math/tex; mode=display">M_1(t)=(U(t)+L(t))/2</script><p>   <em>Step4:</em> Subtract the upper and lower envelope averages from the original sequence <em>Y (t)</em>to get the first function <em>Q1(t)</em>.</p><script type="math/tex; mode=display">Q_1(t)=Y(t)-M_1(t)</script><p>If <em>Q1(t)</em> does not satisfy the two conditions of IMF, that is, the difference between the number of extreme values and the number of zero-crossing points is no more than 1; in any time series range, the local mean value is 0, then the above <em>steps 1-3</em> need to be repeated until IMF conditions are met.</p><script type="math/tex; mode=display">Q_1k(t)=Q_1（k-1)(t)-M_1k(t),IMF_1=Q_1k(t)</script><p>   <em>Step5:</em> Separate the obtained IMF from the original sequence to obtain the remaining sequence <em>P（t）</em>:</p><script type="math/tex; mode=display">P_1(t)=Y(t)-IMF_1</script><p>   <em>Step6:</em> Repeat <em>steps 1-5</em>, and get the remaining eigenmode functions IMF successively. When one of the following conditions is met, the decomposition and screening process is terminated.</p><p><strong><em>a.</em></strong> The remaining sequence is small enough to continue to find the extreme points and envelopes.</p><p><strong><em>b.</em></strong> The remaining function is a monotonic function, and the eigenfunction IMF cannot be decomposed.</p><script type="math/tex; mode=display">Y(t)=\sum_{i=1}^nIMF_i+R_n</script><p>​    After the original sequence is completely decomposed by EMD, several eigenmode functions and a residual wave are obtained, the sum of which is equal to the original sequence.</p><h4 id="Long-and-Short-term-Memory-neural-network"><a href="#Long-and-Short-term-Memory-neural-network" class="headerlink" title="Long and Short-term Memory neural network"></a>Long and Short-term Memory neural network</h4><p>   In recent years, with the continuous exploration of deep learning by scholars, significant progress has been made in the fields of image and speech recognition. At the same time, many scholars have also carried out various in-depth researches on dealing with time-series issues. Because time series data usually has a long memory, and ordinary neural networks do not have memory capabilities, they cannot effectively use sequence information, and the analysis and processing effects of time series are sometimes not ideal. Long Short Term Memory Networks (LSTM), as a special RNN, have strong processing capabilities for time series data with relatively long intervals and delays, and effectively overcome the defects of RNNs in machine learning of gradient disappearance and gradient explosion.</p><p><img src="https://s1.ax1x.com/2020/09/04/wFh4RP.png" alt="wFh4RP.png"></p><p>​                                                           <strong>Fig.2.</strong> <em>The LSTM network structure</em></p><p>   Since a large number of blogs and articles have elaborated on the specific principles of LSTM, this article is an application article that explores the performance of prediction. Due to space reasons, the specific LSTM principle and process will not be repeated.</p><h2 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h2><p>For proving that the proposed model is outstanding on the procedure of short-term prediction,  dataset applied in two experiments are collected from the Shandong wind farms of China.In addition, in order to evaluate the performance of prediction models more reasonably and systematically, we establish an evaluation system to evaluate the performance of each prediction model.</p><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><p>In order to verify the prediction performance of the combined model, the wind speed samples of Shandong wind farm from January 1, 2011 to January 10, 2011 are selected as the verification set. The data length of the data set is 1440. Each data set is divided into two groups: training set and test set, and the allocation ratio is 4:1. In addition, in the single step prediction, the rolling prediction mechanism is used to obtain the later prediction value. The rolling mechanism is shown in the figure below:</p><p><img src="https://s1.ax1x.com/2020/09/04/wFh7qg.png" alt="wFh7qg.png"></p><p>​                                                               <strong>fig.3.</strong> <em>The rolling process</em></p><p>In addition, when inputting data, considering the factors of data dimension and calculation efficiency, the original data is normalized. In the final error calculation, the real prediction value is obtained by inverse normalization. The data input code is as follows:</p><p><img src="https://s1.ax1x.com/2020/09/04/wF4psU.png" alt="wF4psU.png"></p><h4 id="Metrics-Evaluation"><a href="#Metrics-Evaluation" class="headerlink" title="Metrics Evaluation"></a>Metrics Evaluation</h4><p>In order to quantify the performance of the developed system, a variety of error evaluation criteria are used to construct the system evaluation system. Among these indicators, MAPE, MAE, and RMSE investigate the degree of forecasting accuracy. The lower the value of the indicator, the more accurate is the forecasting effect of the model. R^2 mainly measures the forecasting consistency and the forecasting relevance to raw data. </p><p><img src="https://s1.ax1x.com/2020/09/04/wF4EJ1.png" alt="wF4EJ1.png"></p><p><strong><em>Note:</em></strong> This table lists the full names and calculation methods of evaluation indexes included in the evaluation system.</p><h4 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h4><p>   This part uses the wind data of the Shandong wind farm to carry out two groups of simulation experiments. In the previous discussion, we have introduced in detail the principle of data preprocessing (EMD) used in the combined forecasting system. In the first experiment, it was compared with the prediction model using the original wind speed data to explore whether the noise reduction technology is effective. The second experiment is to analyze the performance difference between traditional neural networks and deep learning models in time series prediction. Detailed experimental results are shown in <strong>Table 2.</strong> Bold numbers denote that the value of the index of this model reflects better than those of other models.</p><p><img src="https://s1.ax1x.com/2020/09/04/wF4sWq.png" alt="wF4sWq.png"></p><p><strong>Experiment 1:</strong></p><p>   Table 2 shows that the prediction performance of the data preprocessing technology is significantly improved, which verifies the effectiveness of the hybrid combination strategy proposed in this paper.</p><p>(a) In the experiment of traditional neural networks, the MAPE value of the prediction model after EMD denoising is 2.5534%, while the original data set is used to directly predict the MAPE as high as 7.4099%. At the same time, EMD-NN is still more dominant in evaluating the two indicators of RMSE and MSE.</p><p>(b) Under the framework of deep learning, the MAPE value of EMD-LSTM is reduced by 3.3293% compared with the LSTM model. In addition, R^2 is different from other indicators. The higher the value, the stronger the fitting ability of the prediction system. Among the four comparison models of EMD-LSTM, the R^2 value is the highest, reaching 0.9910.</p><p>   <strong>Remark :</strong> Compared with the original data sequence, the combination method proposed in this paper has achieved better performance, indicating that the selected data preprocessing technology is more effective for the proposed combination model.</p><p><img src="https://s1.ax1x.com/2020/09/04/wF4Zz6.png" alt="wF4Zz6.png"></p><p>​          <strong>Fig.4.</strong>  <em>Actual wind speed sequence and  wind speed value processed by EMD noise reduction technology</em></p><p><strong>Experiment 2:</strong></p><p>   In the comparison of deep learning network (LSTM) and traditional neural network, LSTM is the one with higher prediction accuracy, whether under the original data set or noise reduction data set.</p><p>(a) EMD-LSTM has achieved incomparable advantages in four index values. The values of MAPE, RMSE, MAE and R ^ 2 were 2.3356%, 0.26, 0.20 and 0.9910, respectively, which were 9.32% higher than that of VMD-NN. This is enough to show the superiority and effectiveness of the hybrid model proposed in this paper.</p><p>(b) In the original data set, the advantage of LSTM is more obvious. It has good fitting effect and prediction accuracy. The MAPE value of traditional neural network is 1.754% higher than that of LSTM, which clearly shows that the inherent advantages of deep learning framework are very significant.</p><p> <strong>Remark :</strong> Generally speaking, LSTM neural network not only has outstanding performance in speech recognition and text generation. It also has good performance in time series prediction. The effectiveness and extensibility of deep learning framework are further verified.</p><p><img src="https://s1.ax1x.com/2020/09/04/wF5C1P.png" alt="wF5C1P.png"></p><p>​                    <strong>Fig.5.</strong> <em>Comparison of prediction performance of different prediction models on test set</em></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>​    As a typical renewable energy, wind power has played an irreplaceable role in the development of a low-carbon economy. Due to the natural characteristics of wind speed, accurate and stable forecasting of wind speed is still a difficult point. Therefore, this issue has attracted more and more research attention. Also, an accurate and reliable forecasting system will benefit the management and revenue of wind farms. Therefore, this research proposes a new and comprehensive wind speed prediction framework, which uses data preprocessing, deep learning prediction, and comprehensive evaluation methods. To reduce the interference of the original data, this study considers the “decomposition and aggregation” theory and uses EMD technology to eliminate the noise in the wind speed series. Through the simulation experiment of the Shandong wind field, the performance and applicability of the combined framework are verified. At the same time, it can be concluded that the deep learning algorithm (LSTM) can achieve higher performance and generalization ability under the premise of taking into account the prediction accuracy and stability. Therefore, the developed forecasting model can provide a reliable and effective time series forecasting information in real-time.</p><h2 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h2><p>​     Because most of the output results in neural networks contain certain randomness and probability mechanism, even if the parameter settings are the same, the prediction results of each experiment usually change. Therefore, in future research, metaheuristic methods and simulation optimization algorithms should be developed to adaptively find the optimal initial parameter settings of the neural network, such as the number of hidden layers, the input window dimension, the determination of the weights and thresholds in the neuron, etc., to improve The stability and accuracy of neural networks and deep learning algorithms.</p><h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>​    The appendix briefly shows the codes of some prediction models and evaluation indicators. See the git-hub code column for detailed code.</p><p><img src="https://s1.ax1x.com/2020/09/04/wF5K10.png" alt="wF5K10.png"></p><p>​                                                          LSTM network under the Keras framework</p><p><img src="https://s1.ax1x.com/2020/09/04/wF5rHe.png" alt="wF5rHe.png"></p><p>​                 Traditional neural network structure, including 7 hidden layer nodes and using Adam optimizer</p><p><img src="https://s1.ax1x.com/2020/09/04/wF56Nd.png" alt="wF56Nd.png"></p><p>​                                                     Evaluation system construction</p>]]></content>
      
      
      <categories>
          
          <category> LSTM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep learning </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
